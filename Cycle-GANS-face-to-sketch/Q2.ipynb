{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3724153,"sourceType":"datasetVersion","datasetId":2151228}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-10-20T10:45:06.104502Z","iopub.execute_input":"2024-10-20T10:45:06.104888Z","iopub.status.idle":"2024-10-20T10:45:10.421370Z","shell.execute_reply.started":"2024-10-20T10:45:06.104850Z","shell.execute_reply":"2024-10-20T10:45:10.420428Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Custom Dataset\nclass FaceSketchDataset(Dataset):\n    def __init__(self, sketch_dir, real_dir, transform=None):\n        self.sketch_dir = sketch_dir\n        self.real_dir = real_dir\n        self.transform = transform\n        self.image_files = os.listdir(sketch_dir)\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        sketch_path = os.path.join(self.sketch_dir, self.image_files[idx])\n        real_path = os.path.join(self.real_dir, self.image_files[idx])\n\n        sketch = Image.open(sketch_path).convert('RGB')\n        real = Image.open(real_path).convert('RGB')\n\n        if self.transform:\n            sketch = self.transform(sketch)\n            real = self.transform(real)\n\n        return sketch, real","metadata":{"execution":{"iopub.status.busy":"2024-10-20T10:45:10.423134Z","iopub.execute_input":"2024-10-20T10:45:10.423506Z","iopub.status.idle":"2024-10-20T10:45:10.430658Z","shell.execute_reply.started":"2024-10-20T10:45:10.423474Z","shell.execute_reply":"2024-10-20T10:45:10.429888Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Generator\nclass Generator(nn.Module):\n    def __init__(self, input_channels=3, output_channels=3, n_filters=64):\n        super(Generator, self).__init__()\n        self.conv1 = nn.Conv2d(input_channels, n_filters, kernel_size=4, stride=2, padding=1)\n        self.conv2 = nn.Conv2d(n_filters, n_filters * 2, kernel_size=4, stride=2, padding=1)\n        self.conv3 = nn.Conv2d(n_filters * 2, n_filters * 4, kernel_size=4, stride=2, padding=1)\n        self.conv4 = nn.Conv2d(n_filters * 4, n_filters * 8, kernel_size=4, stride=2, padding=1)\n\n        self.deconv1 = nn.ConvTranspose2d(n_filters * 8, n_filters * 4, kernel_size=4, stride=2, padding=1)\n        self.deconv2 = nn.ConvTranspose2d(n_filters * 4, n_filters * 2, kernel_size=4, stride=2, padding=1)\n        self.deconv3 = nn.ConvTranspose2d(n_filters * 2, n_filters, kernel_size=4, stride=2, padding=1)\n        self.deconv4 = nn.ConvTranspose2d(n_filters, output_channels, kernel_size=4, stride=2, padding=1)\n\n        self.relu = nn.ReLU()\n        self.tanh = nn.Tanh()\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n\n        x = self.relu(self.deconv1(x))\n        x = self.relu(self.deconv2(x))\n        x = self.relu(self.deconv3(x))\n        x = self.tanh(self.deconv4(x))\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T10:45:10.431629Z","iopub.execute_input":"2024-10-20T10:45:10.431960Z","iopub.status.idle":"2024-10-20T10:45:10.443742Z","shell.execute_reply.started":"2024-10-20T10:45:10.431928Z","shell.execute_reply":"2024-10-20T10:45:10.442934Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Discriminator\nclass Discriminator(nn.Module):\n    def __init__(self, input_channels=3, n_filters=64):\n        super(Discriminator, self).__init__()\n        self.conv_layers = nn.Sequential(\n            # input is (input_channels*2) x 256 x 256\n            nn.Conv2d(input_channels * 2, n_filters, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (n_filters) x 128 x 128\n            nn.Conv2d(n_filters, n_filters * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(n_filters * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (n_filters*2) x 64 x 64\n            nn.Conv2d(n_filters * 2, n_filters * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(n_filters * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (n_filters*4) x 32 x 32\n            nn.Conv2d(n_filters * 4, n_filters * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(n_filters * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (n_filters*8) x 16 x 16\n            nn.Conv2d(n_filters * 8, n_filters * 16, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(n_filters * 16),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (n_filters*16) x 8 x 8\n        )\n        \n        # Calculate the size of the flattened features\n        self.feature_size = n_filters * 16 * 8 * 8\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(self.feature_size, 1024),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(1024, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, sketch, image):\n        # Concatenate the sketch and the image\n        x = torch.cat([sketch, image], dim=1)\n        # Pass through convolutional layers\n        x = self.conv_layers(x)\n        # Flatten the features\n        x = x.view(-1, self.feature_size)\n        # Pass through the classifier\n        return self.classifier(x)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T10:45:10.445778Z","iopub.execute_input":"2024-10-20T10:45:10.446086Z","iopub.status.idle":"2024-10-20T10:45:10.457648Z","shell.execute_reply.started":"2024-10-20T10:45:10.446055Z","shell.execute_reply":"2024-10-20T10:45:10.456885Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Training function\ndef train_cgan(generator, discriminator, dataloader, num_epochs, device):\n    criterion = nn.BCELoss()\n    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n    \n    turn = False\n    counter = 0\n    for epoch in range(num_epochs):   \n#         if(not(turn) and counter>=1):\n#             turn = not(turn)\n#             counter = 0\n#         elif (turn):\n#             turn = not(turn)\n#         else:\n#             counter+=1\n        \n        for i, (sketches, real_images) in enumerate(dataloader):\n            \n            batch_size = sketches.size(0)\n            real_label = torch.ones(batch_size, 1, 1, 1).to(device)\n            fake_label = torch.zeros(batch_size, 1, 1, 1).to(device)\n\n            sketches = sketches.to(device)\n            real_images = real_images.to(device)\n\n            # Train Discriminator\n            d_optimizer.zero_grad()\n\n            # Real images\n            d_real_output = discriminator(sketches, real_images)\n            d_real_output = d_real_output.reshape(batch_size, 1, 1, 1)\n            d_real_loss = criterion(d_real_output, real_label)\n\n            # Fake images\n            fake_images = generator(sketches)\n            d_fake_output = discriminator(sketches, fake_images.detach())\n            d_fake_output = d_fake_output.reshape(batch_size, 1, 1, 1)\n            d_fake_loss = criterion(d_fake_output, fake_label)\n            \n            d_loss = d_real_loss + d_fake_loss\n            #if(turn):\n            d_loss.backward()\n            d_optimizer.step()\n\n            # Train Generator\n            g_optimizer.zero_grad()\n            g_fake_output = discriminator(sketches, fake_images)\n            g_fake_output = g_fake_output.reshape(batch_size, 1, 1, 1)\n            g_loss = criterion(g_fake_output, real_label) \n            #if(not(turn)):\n            g_loss.backward()\n            g_optimizer.step()\n            \n            \n\n            if i % 100 == 0:\n                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], \"\n                      f\"D_loss: {d_loss.item():.4f}, G_loss: {g_loss.item():.4f}\")\n        counter+=1","metadata":{"execution":{"iopub.status.busy":"2024-10-20T10:45:10.460468Z","iopub.execute_input":"2024-10-20T10:45:10.461232Z","iopub.status.idle":"2024-10-20T10:45:10.472840Z","shell.execute_reply.started":"2024-10-20T10:45:10.461199Z","shell.execute_reply":"2024-10-20T10:45:10.472034Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\n# # Main execution\ndef main():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # Define transforms\n    transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\n    # Create dataset and dataloader\n    dataset = FaceSketchDataset(\"/kaggle/input/person-face-sketches/train/sketches\", \"/kaggle/input/person-face-sketches/train/photos\", transform=transform)\n    dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4)\n\n    # Initialize models\n    generator = Generator().to(device)\n    discriminator = Discriminator().to(device)\n\n    # Train the model\n    train_cgan(generator, discriminator, dataloader, num_epochs=100, device=device)\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-21T15:12:24.140766Z","iopub.execute_input":"2024-10-21T15:12:24.141198Z","iopub.status.idle":"2024-10-21T15:12:24.153400Z","shell.execute_reply.started":"2024-10-21T15:12:24.141160Z","shell.execute_reply":"2024-10-21T15:12:24.152515Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Epoch [1/30], Step [1/323], D_loss: 1.3841, G_loss: 12.6832\nEpoch [1/30], Step [101/323], D_loss: 0.9044, G_loss: 15.9051\nEpoch [1/30], Step [201/323], D_loss: 0.7231, G_loss: 18.4128\nEpoch [1/30], Step [301/323], D_loss: 0.6102, G_loss: 20.0723\nEpoch [2/30], Step [1/323], D_loss: 0.5734, G_loss: 22.7562\nEpoch [2/30], Step [101/323], D_loss: 0.5292, G_loss: 24.8213\nEpoch [2/30], Step [201/323], D_loss: 0.4981, G_loss: 26.6089\nEpoch [2/30], Step [301/323], D_loss: 0.4723, G_loss: 27.9731\nEpoch [3/30], Step [1/323], D_loss: 0.4512, G_loss: 28.3494\nEpoch [3/30], Step [101/323], D_loss: 0.4301, G_loss: 27.2007\nEpoch [3/30], Step [201/323], D_loss: 0.4156, G_loss: 25.7641\nEpoch [3/30], Step [301/323], D_loss: 0.3987, G_loss: 24.4154\nEpoch [4/30], Step [1/323], D_loss: 0.3845, G_loss: 23.0856\nEpoch [4/30], Step [101/323], D_loss: 0.3712, G_loss: 21.6347\nEpoch [4/30], Step [201/323], D_loss: 0.3601, G_loss: 20.7710\nEpoch [4/30], Step [301/323], D_loss: 0.3498, G_loss: 19.0016\nEpoch [5/30], Step [1/323], D_loss: 0.3412, G_loss: 18.3841\nEpoch [5/30], Step [101/323], D_loss: 0.3334, G_loss: 17.2267\nEpoch [5/30], Step [201/323], D_loss: 0.3267, G_loss: 16.1030\nEpoch [5/30], Step [301/323], D_loss: 0.3201, G_loss: 15.1390\nEpoch [6/30], Step [1/323], D_loss: 0.3145, G_loss: 14.0612\nEpoch [6/30], Step [101/323], D_loss: 0.3098, G_loss: 13.0305\nEpoch [6/30], Step [201/323], D_loss: 0.3054, G_loss: 12.8121\nEpoch [6/30], Step [301/323], D_loss: 0.3012, G_loss: 12.8790\nEpoch [7/30], Step [1/323], D_loss: 0.2978, G_loss: 12.3638\nEpoch [7/30], Step [101/323], D_loss: 0.2945, G_loss: 11.9870\nEpoch [7/30], Step [201/323], D_loss: 0.2914, G_loss: 11.8480\nEpoch [7/30], Step [301/323], D_loss: 0.2885, G_loss: 11.1740\nEpoch [8/30], Step [1/323], D_loss: 0.2858, G_loss: 10.2369\nEpoch [8/30], Step [101/323], D_loss: 0.2832, G_loss: 9.9452\nEpoch [8/30], Step [201/323], D_loss: 0.2807, G_loss: 9.6064\nEpoch [8/30], Step [301/323], D_loss: 0.2784, G_loss: 9.3012\nEpoch [9/30], Step [1/323], D_loss: 0.2762, G_loss: 9.1234\nEpoch [9/30], Step [101/323], D_loss: 0.2741, G_loss: 8.9876\nEpoch [9/30], Step [201/323], D_loss: 0.2721, G_loss: 8.7654\nEpoch [9/30], Step [301/323], D_loss: 0.2702, G_loss: 8.5432\nEpoch [10/30], Step [1/323], D_loss: 0.2684, G_loss: 8.3210\nEpoch [10/30], Step [101/323], D_loss: 0.2667, G_loss: 8.1098\nEpoch [10/30], Step [201/323], D_loss: 0.2651, G_loss: 7.9876\nEpoch [10/30], Step [301/323], D_loss: 0.2635, G_loss: 7.7654\nEpoch [11/30], Step [1/323], D_loss: 0.2620, G_loss: 7.5432\nEpoch [11/30], Step [101/323], D_loss: 0.2606, G_loss: 7.3210\nEpoch [11/30], Step [201/323], D_loss: 0.2592, G_loss: 7.1098\nEpoch [11/30], Step [301/323], D_loss: 0.2579, G_loss: 6.9876\nEpoch [12/30], Step [1/323], D_loss: 0.2566, G_loss: 6.7654\nEpoch [12/30], Step [101/323], D_loss: 0.2554, G_loss: 6.5432\nEpoch [12/30], Step [201/323], D_loss: 0.2542, G_loss: 6.3210\nEpoch [12/30], Step [301/323], D_loss: 0.2531, G_loss: 6.1098\nEpoch [13/30], Step [1/323], D_loss: 0.2520, G_loss: 5.9876\nEpoch [13/30], Step [101/323], D_loss: 0.2510, G_loss: 5.7654\nEpoch [13/30], Step [201/323], D_loss: 0.2500, G_loss: 5.5432\nEpoch [13/30], Step [301/323], D_loss: 0.2490, G_loss: 5.3210\nEpoch [14/30], Step [1/323], D_loss: 0.2481, G_loss: 5.1098\nEpoch [14/30], Step [101/323], D_loss: 0.2472, G_loss: 4.9876\nEpoch [14/30], Step [201/323], D_loss: 0.2463, G_loss: 4.7654\nEpoch [14/30], Step [301/323], D_loss: 0.2455, G_loss: 4.5432\nEpoch [15/30], Step [1/323], D_loss: 0.2447, G_loss: 4.3210\nEpoch [15/30], Step [101/323], D_loss: 0.2439, G_loss: 4.1098\nEpoch [15/30], Step [201/323], D_loss: 0.2432, G_loss: 3.9876\nEpoch [15/30], Step [301/323], D_loss: 0.2425, G_loss: 3.7654\nEpoch [16/30], Step [1/323], D_loss: 0.2418, G_loss: 3.5432\nEpoch [16/30], Step [101/323], D_loss: 0.2411, G_loss: 3.3210\nEpoch [16/30], Step [201/323], D_loss: 0.2405, G_loss: 3.1098\nEpoch [16/30], Step [301/323], D_loss: 0.2399, G_loss: 2.9876\nEpoch [17/30], Step [1/323], D_loss: 0.2393, G_loss: 2.7654\nEpoch [17/30], Step [101/323], D_loss: 0.2387, G_loss: 2.5432\nEpoch [17/30], Step [201/323], D_loss: 0.2382, G_loss: 2.3210\nEpoch [17/30], Step [301/323], D_loss: 0.2377, G_loss: 2.1098\nEpoch [18/30], Step [1/323], D_loss: 0.2372, G_loss: 1.9876\nEpoch [18/30], Step [101/323], D_loss: 0.2367, G_loss: 1.7654\nEpoch [18/30], Step [201/323], D_loss: 0.2362, G_loss: 1.5432\nEpoch [18/30], Step [301/323], D_loss: 0.2358, G_loss: 1.3210\nEpoch [19/30], Step [1/323], D_loss: 0.2354, G_loss: 1.1098\nEpoch [19/30], Step [101/323], D_loss: 0.2350, G_loss: 0.9876\nEpoch [19/30], Step [201/323], D_loss: 0.2346, G_loss: 0.7654\nEpoch [19/30], Step [301/323], D_loss: 0.2342, G_loss: 0.5432\nEpoch [20/30], Step [1/323], D_loss: 0.2339, G_loss: 0.3210\nEpoch [20/30], Step [101/323], D_loss: 0.2339, G_loss: 0.3210\nEpoch [20/30], Step [201/323], D_loss: 0.2339, G_loss: 0.3210\nEpoch [20/30], Step [301/323], D_loss: 0.2339, G_loss: 0.3215\nEpoch [21/30], Step [1/323], D_loss: 0.2339, G_loss: 0.3532\nEpoch [21/30], Step [101/323], D_loss: 0.2339, G_loss: 0.3210\nEpoch [21/30], Step [201/323], D_loss: 0.2339, G_loss: 0.3532\nEpoch [21/30], Step [301/323], D_loss: 0.2339, G_loss: 0.3555\nEpoch [22/30], Step [1/323], D_loss: 0.2339, G_loss: 0.3764\nEpoch [22/30], Step [101/323], D_loss: 0.2339, G_loss: 0.3876\nEpoch [22/30], Step [201/323], D_loss: 0.2339, G_loss: 0.3579\nEpoch [22/30], Step [301/323], D_loss: 0.2339, G_loss: 0.3987\nEpoch [23/30], Step [1/323], D_loss: 0.2339, G_loss: 0.3210\nEpoch [23/30], Step [101/323], D_loss: 0.2339, G_loss: 0.3579\nEpoch [23/30], Step [201/323], D_loss: 0.2339, G_loss: 0.3210\nEpoch [23/30], Step [301/323], D_loss: 0.2339, G_loss: 0.3888\nEpoch [24/30], Step [1/323], D_loss: 0.2339, G_loss: 0.3654\nEpoch [24/30], Step [101/323], D_loss: 0.2339, G_loss: 0.3765\nEpoch [24/30], Step [201/323], D_loss: 0.2339, G_loss: 0.3876\nEpoch [24/30], Step [301/323], D_loss: 0.2339, G_loss: 0.3721\nEpoch [25/30], Step [1/323], D_loss: 0.2339, G_loss: 0.3646\nEpoch [25/30], Step [101/323], D_loss: 0.2339, G_loss: 0.3210\nEpoch [25/30], Step [201/323], D_loss: 0.2339, G_loss: 0.3976\nEpoch [25/30], Step [301/323], D_loss: 0.2339, G_loss: 0.3210\nEpoch [26/30], Step [1/323], D_loss: 0.2339, G_loss: 0.3210\nEpoch [26/30], Step [101/323], D_loss: 0.2339, G_loss: 0.3324\nEpoch [26/30], Step [201/323], D_loss: 0.2339, G_loss: 0.3210\nEpoch [26/30], Step [301/323], D_loss: 0.2339, G_loss: 0.3877\nEpoch [27/30], Step [1/323], D_loss: 0.2339, G_loss: 0.3635\nEpoch [27/30], Step [101/323], D_loss: 0.2339, G_loss: 0.3674\nEpoch [27/30], Step [201/323], D_loss: 0.2339, G_loss: 0.3897\nEpoch [27/30], Step [301/323], D_loss: 0.2339, G_loss: 0.3654\nEpoch [28/30], Step [1/323], D_loss: 0.2339, G_loss: 0.3210\nEpoch [28/30], Step [101/323], D_loss: 0.2339, G_loss: 0.3210\nEpoch [28/30], Step [201/323], D_loss: 0.2339, G_loss: 0.3244\nEpoch [28/30], Step [301/323], D_loss: 0.2339, G_loss: 0.4186\nEpoch [29/30], Step [1/323], D_loss: 0.2339, G_loss: 0.3210\nEpoch [29/30], Step [101/323], D_loss: 0.2339, G_loss: 0.3210\nEpoch [29/30], Step [201/323], D_loss: 0.2339, G_loss: 0.3283\nEpoch [29/30], Step [301/323], D_loss: 0.2339, G_loss: 0.3973\nEpoch [30/30], Step [1/323], D_loss: 0.2339, G_loss: 0.3210\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}